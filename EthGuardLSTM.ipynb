{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samad-mohammed/Etherium-Guard/blob/main/EthGuardLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkSiPxG59slS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('transaction_dataset_pp.csv')"
      ],
      "metadata": {
        "id": "JxEz25rv-S9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.columns = df.columns.str.strip()\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "d7nHemkp-daH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "pQxbJQdx_OD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_experiment = df.copy()\n",
        "\n",
        "df_experiment.FLAG.value_counts()"
      ],
      "metadata": {
        "id": "HdBtydpf_fcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "y = df_experiment.FLAG\n",
        "X = df_experiment.drop(columns='FLAG')\n",
        "labels = y.unique()\n",
        "\n",
        "classes = y.nunique()\n",
        "print(X.shape)\n",
        "print(\"number of labels:\", classes)\n",
        "print(\"instances per label\\n\", y.value_counts())\n",
        "print(\"labels:\", labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
        "\n",
        "print(\"after spliting the data:\\n\")\n",
        "print(\"training data length:\", len(X_train))\n",
        "print(\"test data length:\", len(X_test))\n",
        "# pr"
      ],
      "metadata": {
        "id": "ZkMdmST_-vq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bi_train_y = y_train.copy()\n",
        "\n",
        "print(bi_train_y.unique())\n",
        "# bi_train.head(2)\n",
        "\n",
        "bi_test_y = y_test.copy()\n",
        "\n",
        "print(bi_test_y.unique())\n",
        "# bi_train.head(2)\n",
        "\n",
        "### switch for binary!\n",
        "y_train = bi_train_y\n",
        "y_test = bi_test_y"
      ],
      "metadata": {
        "id": "kUmZu7SzAJD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "le = LabelEncoder()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "labels_dict = dict(zip(le.classes_, range(len(le.classes_))))\n",
        "print(labels_dict)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from collections import Counter\n",
        "over = SMOTE(sampling_strategy='not majority', n_jobs=-1)\n",
        "under = RandomUnderSampler(sampling_strategy=\n",
        "                             {labels_dict[0]:200000})\n",
        "\n",
        "steps = [('o', over)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
        "counter = Counter(y_train)\n",
        "print(counter)"
      ],
      "metadata": {
        "id": "QqkLzIjfAU7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "0IJ507mjAt0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "id": "0DA5jdlWAxm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.describe()\n"
      ],
      "metadata": {
        "id": "cK-Wg5mhA1fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test_lstm = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "print(f\"shape of X_train:\", X_train_lstm.shape)\n",
        "print(f\"shape of X_test:\", X_test_lstm.shape)"
      ],
      "metadata": {
        "id": "KkalBupNBFUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model, Sequential, Input, backend\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "n_classes = len(le.classes_)\n",
        "print(f\"num of classes:{n_classes}\")\n",
        "n_features = X_train_lstm.shape[2]\n",
        "def multiClassModel(n_features, n_classes=9):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(None, n_features)))\n",
        "    model.add(LSTM(units=30))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(n_classes, activation=\"softmax\", name=\"softmax\"))\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='Adam')\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "bVdOX6IbBKWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(patience=20, mode='min', restore_best_weights=True)\n",
        "backend.clear_session()\n",
        "model = multiClassModel(n_features, n_classes)\n",
        "history = model.fit(X_train_lstm, y_train, \n",
        "                    epochs=200, batch_size=64, validation_split=0.2, callbacks=[callback])\n",
        "### check the loss trend of epochs\n",
        "pd.DataFrame(history.history).plot(kind='line', xlabel='epochs', figsize=(8, 6))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "teN3lu_pBNE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred_prob = model.predict(X_train_lstm)\n",
        "y_test_pred_prob = model.predict(X_test_lstm)\n",
        "y_train_pred = np.argmax(y_train_pred_prob, axis=1)\n",
        "y_test_pred = np.argmax(y_test_pred_prob, axis=1)\n"
      ],
      "metadata": {
        "id": "AU3iGky5BZep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "cm = confusion_matrix(y_train, y_train_pred)\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_).plot(ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rMxZV5G9BdCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_).plot(ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c0GshqLhBhq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multilabel_matrix(y_true, y_pred, labels=None):\n",
        "    mlm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    df_performance = pd.DataFrame(index=labels, columns=['accuracy', 'precision', 'recall', 'f1_score'])\n",
        "    for i, label in enumerate(labels):\n",
        "        tn, fp, fn, tp = mlm[i].ravel()\n",
        "        accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "\n",
        "        f1_score = 2*precision * recall / (precision + recall)\n",
        "        df_performance.loc[label] = [round(accuracy, 4), round(precision,4), \\\n",
        "                                     round(recall, 4), round(f1_score,4)]\n",
        "    return df_performance"
      ],
      "metadata": {
        "id": "NhWWgoEWBmqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from itertools import cycle\n",
        "def RoC_Curve(y_score, y, labels, title): \n",
        "    y_cat = to_categorical(y)\n",
        "    \n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    lw = 2\n",
        "    # First aggregate all false positive rates\n",
        "    n_classes = len(labels)\n",
        "#     print('n_classes:', n_classes)\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_cat[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_cat.ravel(), y_score.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    # First aggregate all false positive rates\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "    # Then interpolate all ROC curves at this points\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(n_classes):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "    # Finally average it and compute AUC\n",
        "    mean_tpr /= n_classes\n",
        "\n",
        "    fpr[\"macro\"] = all_fpr\n",
        "    tpr[\"macro\"] = mean_tpr\n",
        "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "    # Plot all ROC curves\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "             label='micro-average ROC curve (area = {0:0.4f})'\n",
        "                   ''.format(roc_auc[\"micro\"]),\n",
        "             color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "             label='macro-average ROC curve (area = {0:0.4f})'\n",
        "                   ''.format(roc_auc[\"macro\"]),\n",
        "             color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        plt.plot(fpr[i], tpr[i], lw=lw,\n",
        "                 label=f'ROC curve of class {labels[i]} (area = {roc_auc[i]:0.4f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "C7rUJDo7BtQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "y_train_pred_labels = le.inverse_transform(y_train_pred)\n",
        "y_train_labels = le.inverse_transform(y_train)\n",
        "print(classification_report(y_train_labels, y_train_pred_labels))\n",
        "performance = multilabel_matrix(y_train_pred_labels, y_train_labels, labels=le.classes_)\n",
        "performance"
      ],
      "metadata": {
        "id": "JUIBr2cvB9LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_labels = le.inverse_transform(y_test_pred)\n",
        "y_test_true_labels = le.inverse_transform(y_test)\n",
        "print(classification_report(y_test_true_labels,y_test_pred_labels))"
      ],
      "metadata": {
        "id": "SEk7H68CB1Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance = multilabel_matrix(y_test_true_labels, y_test_pred_labels, labels=le.classes_)\n",
        "performance"
      ],
      "metadata": {
        "id": "PiekUa6qCie0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RoC_Curve(y_train_pred_prob, y_train, le.classes_, title='ROC for CIC-IDS2017 training set')"
      ],
      "metadata": {
        "id": "URWffJXVCkYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RoC_Curve(y_test_pred_prob, y_test, le.classes_, title='ROC for CIC-IDS2017 test set')"
      ],
      "metadata": {
        "id": "WSTtYWBaCndr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'pipeline.h5')"
      ],
      "metadata": {
        "id": "5nLCAXf6C2d8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}